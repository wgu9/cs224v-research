# é•¿å¯¹è¯å¤„ç†ï¼šSessionç®¡ç†ä¸åµŒå¥—ç»“æ„è®¾è®¡

## ğŸ¯ é—®é¢˜å®šä¹‰

**åœºæ™¯**ï¼šcursorå¯¹è¯éå¸¸é•¿ï¼ˆå‡ ä¸‡è¡Œï¼Œ50ä¸ªuser queryï¼‰ï¼Œç›´æ¥å¤„ç†ä¼šé‡åˆ°ï¼š
1. **Tokené™åˆ¶**ï¼šå•ä¸ªLLMè°ƒç”¨æ— æ³•å¤„ç†å…¨éƒ¨å†…å®¹
2. **ä»»åŠ¡æ··åˆ**ï¼šä¸åŒqueryå¯èƒ½æ˜¯å®Œå…¨ä¸åŒçš„ä»»åŠ¡
3. **ä¸Šä¸‹æ–‡ä¾èµ–**ï¼šåŒsessionå†…çš„queryå¯èƒ½æœ‰ä¾èµ–å…³ç³»
4. **æ•ˆç‡é—®é¢˜**ï¼šä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰å†…å®¹æµªè´¹è®¡ç®—èµ„æº

**ç›®æ ‡**ï¼šè®¾è®¡åµŒå¥—ç»“æ„ï¼Œæ—¢èƒ½å¤„ç†é•¿å¯¹è¯ï¼Œåˆèƒ½ä¿ç•™ä¸Šä¸‹æ–‡ï¼Œè¿˜èƒ½ç‹¬ç«‹åˆ†ææ¯ä¸ªquery-answer pairã€‚

---

## ğŸ“ æ•°æ®ç»“æ„è®¾è®¡

### 1. Session Metadataï¼ˆä¼šè¯å…ƒæ•°æ®ï¼‰

å®šä¹‰ä½ç½®ï¼š`types/cursor-chat/session.ts`

```typescript
export interface SessionMetadata {
  session_id: string;              // å”¯ä¸€æ ‡è¯†ï¼Œå¦‚ "s_20251026_cursor_001"
  source: string;                  // "cursor" | "claude" | "aider"
  start_datetime: string;          // ISO8601: "2025-10-26T10:00:00Z"
  end_datetime?: string;           // å¯é€‰ï¼Œä¼šè¯ç»“æŸæ—¶é—´
  total_queries: number;           // user queryæ€»æ•°ï¼Œå¦‚ 50
  total_turns: number;             // æ€»è½®æ¬¡ï¼ˆuser + assistantï¼‰ï¼Œå¦‚ 100
  project_context?: string;        // é¡¹ç›®ä¸Šä¸‹æ–‡ï¼ˆä»ç¬¬ä¸€è½®æ¨æ–­ï¼‰
  overall_objective?: string;      // æ•´ä½“ç›®æ ‡ï¼ˆLLMæ¨æ–­ï¼‰
  tags?: string[];                 // æ ‡ç­¾ï¼Œå¦‚ ["documentation", "refactoring"]
  meta?: Record<string, any>;      // æ‰©å±•å­—æ®µ
}
```

### 2. Query-Answer Pair Metadataï¼ˆæ¯ä¸ªQAå¯¹çš„å…ƒæ•°æ®ï¼‰

å®šä¹‰ä½ç½®ï¼š`types/cursor-chat/pair.ts`

```typescript
export interface QueryAnswerPair {
  pair_id: string;                 // "s_20251026_cursor_001_q05"
  session_id: string;              // å…³è”åˆ°session
  query_index: number;             // 1, 2, 3, ..., 50

  // æ—¶é—´ä¿¡æ¯
  timestamp?: string;              // è¯¥queryçš„æ—¶é—´

  // å†…å®¹å¼•ç”¨
  markdown_path: string;           // è¯¥pairçš„markdownæ–‡ä»¶è·¯å¾„

  // ä¸Šä¸‹æ–‡ä¿¡æ¯
  prev_pair_id?: string;           // å‰ä¸€ä¸ªpairçš„ID
  has_context_dependency: boolean; // æ˜¯å¦ä¾èµ–å‰é¢çš„ä¸Šä¸‹æ–‡

  // ä»»åŠ¡ä¿¡æ¯ï¼ˆLLMæå–ï¼‰
  objective: string;               // è¯¥queryçš„å…·ä½“ç›®æ ‡
  task_type: TaskType;             // "doc" | "code" | "test" | "debug" | "refactor"
  related_files: string[];         // æåˆ°çš„æ–‡ä»¶
  is_followup: boolean;            // æ˜¯å¦æ˜¯å‰ä¸€ä¸ªqueryçš„åç»­

  // Goal.jsonå¼•ç”¨
  goal_json_path?: string;         // è¯¥pairç”Ÿæˆçš„goal.jsonè·¯å¾„

  meta?: Record<string, any>;
}

export type TaskType = 'doc' | 'code' | 'test' | 'debug' | 'refactor' | 'config';
```

### 3. ç›®å½•ç»“æ„

```
data/sessions/<session_id>/
â”œâ”€â”€ session.json                      # Session metadata
â”œâ”€â”€ pairs.json                        # æ‰€æœ‰QA pairsçš„å…ƒæ•°æ®åˆ—è¡¨
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ full_conversation.md          # åŸå§‹å®Œæ•´å¯¹è¯
â”œâ”€â”€ pairs/
â”‚   â”œâ”€â”€ q01_translate_readme.md       # Query 1çš„QA pair
â”‚   â”œâ”€â”€ q02_fix_test.md               # Query 2çš„QA pair
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ q50_final_review.md           # Query 50çš„QA pair
â”œâ”€â”€ goals/
â”‚   â”œâ”€â”€ q01_goal.json                 # Query 1çš„goal.json
â”‚   â”œâ”€â”€ q02_goal.json                 # Query 2çš„goal.json
â”‚   â””â”€â”€ ...
â””â”€â”€ runs/
    â”œâ”€â”€ q01/                          # Query 1çš„Q1åˆ†æç»“æœ
    â”‚   â”œâ”€â”€ events.jsonl
    â”‚   â””â”€â”€ guards.jsonl
    â”œâ”€â”€ q02/
    â”‚   â”œâ”€â”€ events.jsonl
    â”‚   â””â”€â”€ guards.jsonl
    â””â”€â”€ ...
```

---

## ğŸ”ª é•¿å¯¹è¯æ‹†åˆ†ç­–ç•¥

### ç­–ç•¥1ï¼šåŸºäºPatternçš„æ™ºèƒ½æ‹†åˆ†

ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¯†åˆ«User-Assistantè½®æ¬¡è¾¹ç•Œï¼š

```python
import re
from typing import List, Tuple

def split_conversation(full_md: str) -> List[Tuple[int, str, str]]:
    """
    æ‹†åˆ†é•¿å¯¹è¯ä¸ºå¤šä¸ªquery-answer pairs

    Returns:
        List of (query_index, user_message, assistant_messages)
    """
    pairs = []
    lines = full_md.split('\n')

    current_user = None
    current_assistant = []
    query_idx = 0

    i = 0
    while i < len(lines):
        line = lines[i]

        # æ£€æµ‹åˆ°æ–°çš„Useræ¶ˆæ¯
        if re.match(r'\*\*User\*\*', line, re.IGNORECASE):
            # ä¿å­˜å‰ä¸€ä¸ªpair
            if current_user is not None:
                pairs.append((
                    query_idx,
                    current_user,
                    '\n\n'.join(current_assistant)
                ))
                query_idx += 1

            # å¼€å§‹æ–°çš„pair
            current_user = ''
            current_assistant = []
            i += 1

            # æ”¶é›†useræ¶ˆæ¯ç›´åˆ°é‡åˆ°assistant
            while i < len(lines) and not re.match(
                r'\*\*(?:Cursor|Claude|Assistant)\*\*',
                lines[i],
                re.IGNORECASE
            ):
                current_user += lines[i] + '\n'
                i += 1
            continue

        # æ£€æµ‹åˆ°Assistantæ¶ˆæ¯
        if re.match(r'\*\*(?:Cursor|Claude|Assistant)\*\*', lines[i], re.IGNORECASE):
            i += 1
            assistant_msg = ''
            # æ”¶é›†assistantæ¶ˆæ¯ç›´åˆ°é‡åˆ°ä¸‹ä¸€ä¸ªUser
            while i < len(lines) and not re.match(r'\*\*User\*\*', lines[i], re.IGNORECASE):
                assistant_msg += lines[i] + '\n'
                i += 1
            current_assistant.append(assistant_msg)
            continue

        i += 1

    # ä¿å­˜æœ€åä¸€ä¸ªpair
    if current_user is not None:
        pairs.append((query_idx, current_user, '\n\n'.join(current_assistant)))

    return pairs
```

### ç­–ç•¥2ï¼šä¿ç•™ä¸Šä¸‹æ–‡çš„æ–¹å¼

æ¯ä¸ªpairçš„markdownåŒ…å«ä¸¤éƒ¨åˆ†ï¼š

```markdown
# Query 5: Fix authentication bug

## Context from Previous Query (Q4)

**Previous User Request:**
> Add user registration feature

**Previous Assistant Summary:**
> Created user registration endpoint in src/auth/register.py

---

## Current Query-Answer

**User**
Fix the authentication bug in login.py

**Cursor**
I'll fix the token validation logic...
```

---

## ğŸ¤– LLMå¤„ç†æµç¨‹

### Phase 1: æå–Session Metadata

**è¾“å…¥**ï¼šå®Œæ•´å¯¹è¯çš„å‰2000è¡Œ + æœ€å500è¡Œ

**Prompt**ï¼š
```python
EXTRACT_SESSION_METADATA_PROMPT = """
Analyze this long cursor conversation and extract session-level metadata.

**Input**: First 2000 lines + last 500 lines of the conversation

**Task**: Generate session metadata JSON

**Schema**:
```json
{
  "session_id": "s_<timestamp>_<source>_<seq>",
  "source": "cursor",
  "start_datetime": "2025-10-26T10:00:00Z",
  "total_queries": 50,
  "project_context": "Python web API project",
  "overall_objective": "Add authentication and internationalization",
  "tags": ["authentication", "i18n", "refactoring"]
}
```

**Instructions**:
1. Infer project_context from the first few queries
2. Summarize overall_objective across all queries
3. Count total_queries by counting "**User**" occurrences
4. Extract tags based on task types mentioned

Output pure JSON.
"""
```

**å®ç°**ï¼š
```python
def extract_session_metadata(full_md: str, api_key: str) -> dict:
    """ä»å®Œæ•´å¯¹è¯æå–session metadata"""
    # å–å‰2000è¡Œ + å500è¡Œ
    lines = full_md.split('\n')
    sample = '\n'.join(lines[:2000] + ['...'] + lines[-500:])

    client = anthropic.Anthropic(api_key=api_key)
    response = client.messages.create(
        model="claude-3-5-sonnet-20241022",
        max_tokens=1000,
        system=EXTRACT_SESSION_METADATA_PROMPT,
        messages=[{"role": "user", "content": sample}]
    )

    content = response.content[0].text.strip()
    if content.startswith("```"):
        content = '\n'.join(content.split('\n')[1:-1])

    meta = json.loads(content)

    # ç”Ÿæˆsession_idå¦‚æœä¸å­˜åœ¨
    if not meta.get('session_id'):
        import time
        meta['session_id'] = f"s_{int(time.time())}_{meta.get('source', 'cursor')}"

    return meta
```

### Phase 2: ä¸ºæ¯ä¸ªQA Pairç”ŸæˆMetadata

**è¾“å…¥**ï¼š
- å½“å‰pairçš„å®Œæ•´å†…å®¹
- å‰ä¸€ä¸ªpairçš„å®Œæ•´å†…å®¹ï¼ˆå¯é€‰ï¼‰

**Prompt**ï¼š
```python
EXTRACT_PAIR_METADATA_PROMPT = """
Analyze this query-answer pair and extract metadata.

**Context** (if exists):
Previous query-answer pair for reference

**Current Query-Answer**:
{current_pair}

**Task**: Generate pair metadata JSON

**Schema**:
```json
{
  "pair_id": "s_xxx_q05",
  "query_index": 5,
  "objective": "Fix authentication bug in login.py",
  "task_type": "debug",
  "related_files": ["src/auth/login.py"],
  "is_followup": true,
  "has_context_dependency": true
}
```

**Task Types**:
- "doc": Documentation/translation
- "code": New feature/implementation
- "debug": Bug fix
- "test": Testing
- "refactor": Code refactoring
- "config": Configuration change

**is_followup**: true if this query builds on the previous query
**has_context_dependency**: true if understanding this query requires previous context

Output pure JSON.
"""
```

**å®ç°**ï¼š
```python
def extract_pair_metadata(
    pair_content: str,
    query_index: int,
    session_id: str,
    api_key: str
) -> dict:
    """ä»å•ä¸ªQA pairæå–metadata"""
    client = anthropic.Anthropic(api_key=api_key)

    response = client.messages.create(
        model="claude-3-5-sonnet-20241022",
        max_tokens=1000,
        system=EXTRACT_PAIR_METADATA_PROMPT,
        messages=[{"role": "user", "content": pair_content[:4000]}]
    )

    content = response.content[0].text.strip()
    if content.startswith("```"):
        content = '\n'.join(content.split('\n')[1:-1])

    meta = json.loads(content)
    meta['query_index'] = query_index
    meta['session_id'] = session_id
    meta['pair_id'] = f"{session_id}_q{query_index:02d}"

    return meta
```

### Phase 3: ä¸ºæ¯ä¸ªPairç”ŸæˆGoal.json

å¯¹äºæ¯ä¸ªpairï¼Œæ ¹æ®æ˜¯å¦æœ‰ä¸Šä¸‹æ–‡ä¾èµ–ï¼š

```python
def generate_goal_for_pair(
    pair: QueryAnswerPair,
    pair_content: str,
    prev_pair_content: Optional[str] = None,
    api_key: str
) -> dict:
    """ä¸ºå•ä¸ªQA pairç”Ÿæˆgoal.json"""

    if pair.has_context_dependency and prev_pair_content:
        # åŒ…å«å‰ä¸€ä¸ªpairçš„å†…å®¹
        context = f"""
## Previous Query-Answer:
{prev_pair_content}

## Current Query-Answer:
{pair_content}
"""
    else:
        # ç‹¬ç«‹åˆ†æ
        context = pair_content

    # è°ƒç”¨ä¹‹å‰è®¾è®¡çš„generate_goal_from_cursor
    goal = generate_goal_from_cursor(context, api_key)
    goal["run_id"] = f"{pair.session_id}_q{pair.query_index:02d}"

    return goal
```

---

## ğŸ”„ å®Œæ•´å¤„ç†æµç¨‹

### ä¸»æµç¨‹å®ç°

```python
#!/usr/bin/env python3
"""
å¤„ç†é•¿å¯¹è¯ï¼šæ‹†åˆ† â†’ æå–metadata â†’ ç”Ÿæˆgoal.json
"""

import json
import pathlib
from typing import List, Optional
import anthropic

def process_long_conversation(
    full_md_path: str,
    output_dir: str,
    api_key: str
) -> str:
    """
    å¤„ç†é•¿å¯¹è¯çš„å®Œæ•´æµç¨‹

    Args:
        full_md_path: å®Œæ•´å¯¹è¯markdownè·¯å¾„
        output_dir: è¾“å‡ºç›®å½•ï¼ˆdata/sessionsï¼‰
        api_key: Anthropic API key

    Returns:
        session_id
    """
    full_md = pathlib.Path(full_md_path).read_text(encoding='utf-8')

    # Step 1: æå–session metadata
    print("ğŸ“Š Extracting session metadata...")
    session_meta = extract_session_metadata(full_md, api_key)
    session_id = session_meta['session_id']

    # åˆ›å»ºç›®å½•ç»“æ„
    session_dir = pathlib.Path(output_dir) / session_id
    (session_dir / 'raw').mkdir(parents=True, exist_ok=True)
    (session_dir / 'pairs').mkdir(parents=True, exist_ok=True)
    (session_dir / 'goals').mkdir(parents=True, exist_ok=True)

    # ä¿å­˜åŸå§‹å¯¹è¯
    (session_dir / 'raw' / 'full_conversation.md').write_text(full_md, encoding='utf-8')

    # Step 2: æ‹†åˆ†å¯¹è¯
    print("ğŸ”ª Splitting conversation into query-answer pairs...")
    pairs = split_conversation(full_md)
    print(f"   Found {len(pairs)} query-answer pairs")

    # Step 3: ä¸ºæ¯ä¸ªpairç”Ÿæˆmetadataå’Œgoal.json
    pair_metas = []
    prev_pair_content = None

    for idx, (query_idx, user_msg, assistant_msg) in enumerate(pairs):
        print(f"\nğŸ“ Processing Q{idx+1}/{len(pairs)}...")

        # æ„å»ºpairå†…å®¹
        pair_content = f"**User**\n{user_msg}\n\n**Assistant**\n{assistant_msg}"

        # å¦‚æœéœ€è¦ä¸Šä¸‹æ–‡ï¼Œé™„åŠ å‰ä¸€ä¸ªpair
        if idx > 0:
            pair_content_with_context = f"""## Previous Query-Answer:
{prev_pair_content}

---

## Current Query-Answer:
{pair_content}
"""
        else:
            pair_content_with_context = pair_content

        # æå–pair metadata
        pair_meta = extract_pair_metadata(
            pair_content_with_context,
            idx + 1,
            session_id,
            api_key
        )

        # ä¿å­˜pair markdown
        pair_filename = f"q{idx+1:02d}_{sanitize_filename(pair_meta['objective'])}.md"
        pair_path = session_dir / 'pairs' / pair_filename

        # å¦‚æœæœ‰ä¸Šä¸‹æ–‡ä¾èµ–ï¼Œä¿å­˜å¸¦ä¸Šä¸‹æ–‡çš„ç‰ˆæœ¬
        if pair_meta.get('has_context_dependency') and prev_pair_content:
            final_content = f"""# Query {idx+1}: {pair_meta['objective']}

## Context from Previous Query

{prev_pair_content[:500]}...

---

## Current Query-Answer

{pair_content}
"""
        else:
            final_content = f"""# Query {idx+1}: {pair_meta['objective']}

{pair_content}
"""

        pair_path.write_text(final_content, encoding='utf-8')
        pair_meta['markdown_path'] = str(pair_path)

        # ç”Ÿæˆgoal.json
        print(f"   ğŸ¯ Generating goal.json for Q{idx+1}...")

        # æ ¹æ®has_context_dependencyå†³å®šè¾“å…¥
        goal_input = pair_content_with_context if pair_meta.get('has_context_dependency') else pair_content
        goal = generate_goal_from_cursor(goal_input, api_key)
        goal['run_id'] = f"{session_id}_q{idx+1:02d}"

        goal_path = session_dir / 'goals' / f"q{idx+1:02d}_goal.json"
        goal_path.write_text(json.dumps(goal, indent=2, ensure_ascii=False), encoding='utf-8')
        pair_meta['goal_json_path'] = str(goal_path)

        pair_metas.append(pair_meta)
        prev_pair_content = pair_content

        print(f"   âœ… Q{idx+1}: {pair_meta['objective'][:50]}...")

    # Step 4: ä¿å­˜session metadataå’Œpairsåˆ—è¡¨
    session_meta['total_queries'] = len(pairs)
    (session_dir / 'session.json').write_text(
        json.dumps(session_meta, indent=2, ensure_ascii=False),
        encoding='utf-8'
    )
    (session_dir / 'pairs.json').write_text(
        json.dumps(pair_metas, indent=2, ensure_ascii=False),
        encoding='utf-8'
    )

    print(f"\nâœ… Session processed: {session_id}")
    print(f"   ğŸ“ Output: {session_dir}")
    print(f"   ğŸ“Š {len(pairs)} query-answer pairs extracted")

    return session_id


def sanitize_filename(s: str) -> str:
    """æ¸…ç†æ–‡ä»¶å"""
    import re
    s = re.sub(r'[^\w\s-]', '', s)
    s = re.sub(r'[-\s]+', '_', s)
    return s[:50].lower()


# ============================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================

if __name__ == "__main__":
    import sys
    import os

    if len(sys.argv) < 2:
        print("Usage: python process_long_conversation.py <full_conversation.md>")
        print("\nRequires: ANTHROPIC_API_KEY environment variable")
        sys.exit(1)

    api_key = os.environ.get("ANTHROPIC_API_KEY")
    if not api_key:
        print("Error: ANTHROPIC_API_KEY not set")
        sys.exit(1)

    full_md_path = sys.argv[1]
    output_dir = "data/sessions"

    session_id = process_long_conversation(full_md_path, output_dir, api_key)

    print(f"\nğŸ‰ Done! Session: {session_id}")
    print(f"\nNext steps:")
    print(f"  1. Review session.json and pairs.json")
    print(f"  2. Run Q1 analysis on each pair:")
    print(f"     for goal in data/sessions/{session_id}/goals/*.json; do")
    print(f"       PYTHONPATH=. python tools/chat2events.py \\")
    print(f"         data/sessions/{session_id}/runs/$(basename $goal .json)")
    print(f"     done")
```

---

## ğŸ¯ ä¸Šä¸‹æ–‡ä¿ç•™ç­–ç•¥ï¼ˆå…³é”®è®¾è®¡ï¼‰

### ä¸¤ç§æ¨¡å¼

#### æ¨¡å¼Aï¼šè½»é‡çº§ï¼ˆé»˜è®¤æ¨èï¼‰
```python
# æ€»æ˜¯é™„åŠ å®Œæ•´çš„å‰ä¸€ä¸ªpair
if idx > 0:
    full_input = prev_pair_content + "\n---\n" + current_pair_content
else:
    full_input = current_pair_content

# LLMä¼šè‡ªåŠ¨åˆ¤æ–­has_context_dependency
pair_meta = extract_pair_metadata(full_input, ...)
```

#### æ¨¡å¼Bï¼šæ™ºèƒ½é€‰æ‹©
```python
# å…ˆç”¨è½»é‡promptåˆ¤æ–­æ˜¯å¦éœ€è¦ä¸Šä¸‹æ–‡
needs_context = check_if_needs_context(current_pair_content)

if needs_context and prev_pair_content:
    full_input = prev_pair_content + "\n---\n" + current_pair_content
else:
    full_input = current_pair_content
```

### æ¨èç­–ç•¥

**é»˜è®¤ï¼šæ€»æ˜¯é™„åŠ å‰ä¸€ä¸ªpair**
- ä¼˜ç‚¹ï¼šLLMèƒ½çœ‹åˆ°å®Œæ•´ä¸Šä¸‹æ–‡ï¼Œåˆ¤æ–­æ›´å‡†ç¡®
- ç¼ºç‚¹ï¼štokenæ¶ˆè€—ç¨é«˜
- é€‚ç”¨ï¼šå¤§å¤šæ•°åœºæ™¯

**é™åˆ¶ï¼šåªæœ‰å‰500å­—ç¬¦**
```python
prev_summary = prev_pair_content[:500] + "..."
```

---

## ğŸ“Š æ•°æ®æŸ¥è¯¢ä¸åˆ†æ

### æŸ¥è¯¢Sessionæ¦‚è§ˆ

```python
def get_session_overview(session_id: str) -> dict:
    """è·å–sessionæ¦‚è§ˆ"""
    session_dir = pathlib.Path(f"data/sessions/{session_id}")

    session_meta = json.loads((session_dir / 'session.json').read_text())
    pairs_meta = json.loads((session_dir / 'pairs.json').read_text())

    return {
        "session": session_meta,
        "total_queries": len(pairs_meta),
        "task_types": [p['task_type'] for p in pairs_meta],
        "followup_count": sum(1 for p in pairs_meta if p.get('is_followup')),
        "context_dependent_count": sum(1 for p in pairs_meta if p.get('has_context_dependency'))
    }
```

### æŸ¥è¯¢ç‰¹å®šQuery

```python
def get_query_details(session_id: str, query_index: int) -> dict:
    """è·å–ç‰¹å®šqueryçš„è¯¦ç»†ä¿¡æ¯"""
    session_dir = pathlib.Path(f"data/sessions/{session_id}")
    pairs_meta = json.loads((session_dir / 'pairs.json').read_text())

    pair = pairs_meta[query_index - 1]
    goal = json.loads(pathlib.Path(pair['goal_json_path']).read_text())

    # æ£€æŸ¥æ˜¯å¦å·²è¿è¡ŒQ1åˆ†æ
    run_dir = session_dir / 'runs' / f"q{query_index:02d}"
    if run_dir.exists():
        events = [json.loads(line) for line in (run_dir / 'events.jsonl').read_text().splitlines()]
        guards = [json.loads(line) for line in (run_dir / 'guards.jsonl').read_text().splitlines()]
    else:
        events = None
        guards = None

    return {
        "pair": pair,
        "goal": goal,
        "events": events,
        "guards": guards,
        "has_drift": any(g['action'] != 'ok' for g in guards) if guards else None
    }
```

---

## ğŸ§ª æµ‹è¯•ç¤ºä¾‹

### ç¤ºä¾‹ï¼šå¤„ç†10287è¡Œçš„å¯¹è¯

```bash
# 1. å¤„ç†é•¿å¯¹è¯
export ANTHROPIC_API_KEY=sk-xxx
python tools/process_long_conversation.py \
  spot-test/cursor_document_updates_and_alignment_s.md

# è¾“å‡ºï¼š
# ğŸ“Š Extracting session metadata...
#    âœ… Session: s_1730001234_cursor
# ğŸ”ª Splitting conversation...
#    Found 50 query-answer pairs
# ğŸ“ Processing Q1/50...
#    ğŸ¯ Generating goal.json for Q1...
#    âœ… Q1: Update README documentation
# ğŸ“ Processing Q2/50...
#    ğŸ¯ Generating goal.json for Q2...
#    âœ… Q2: Fix typo in setup.py
# ...
# âœ… Session processed: s_1730001234_cursor

# 2. æŸ¥çœ‹sessionç»“æ„
tree data/sessions/s_1730001234_cursor/
# â”œâ”€â”€ session.json
# â”œâ”€â”€ pairs.json
# â”œâ”€â”€ raw/
# â”‚   â””â”€â”€ full_conversation.md
# â”œâ”€â”€ pairs/
# â”‚   â”œâ”€â”€ q01_update_readme_documentation.md
# â”‚   â”œâ”€â”€ q02_fix_typo_in_setup.md
# â”‚   â””â”€â”€ ...
# â””â”€â”€ goals/
#     â”œâ”€â”€ q01_goal.json
#     â”œâ”€â”€ q02_goal.json
#     â””â”€â”€ ...

# 3. å¯¹æ¯ä¸ªpairè¿è¡ŒQ1åˆ†æ
for i in {1..50}; do
  pair_id=$(printf "q%02d" $i)
  echo "Analyzing $pair_id..."

  # åˆ›å»ºrunç›®å½•
  mkdir -p data/sessions/s_1730001234_cursor/runs/$pair_id

  # è¯»å–goal.json
  goal_path=data/sessions/s_1730001234_cursor/goals/${pair_id}_goal.json

  # è¯»å–pair markdown
  pair_md=$(ls data/sessions/s_1730001234_cursor/pairs/${pair_id}_*.md)

  # è¿è¡ŒQ1åˆ†æ
  PYTHONPATH=. python tools/chat2events.py \
    --cursor-md="$pair_md" \
    --goal="$goal_path" \
    --output=data/sessions/s_1730001234_cursor/runs/$pair_id
done
```

---

## âœ… æ€»ç»“

### æ ¸å¿ƒè®¾è®¡åŸåˆ™

| è®¾è®¡ç‚¹ | å®ç°æ–¹æ¡ˆ |
|--------|---------|
| **Sessionç®¡ç†** | ç‹¬ç«‹çš„session.jsonï¼ŒåŒ…å«æ•´ä½“metadata |
| **Queryæ‹†åˆ†** | æ­£åˆ™åŒ¹é…`**User**`å’Œ`**Assistant**`è¾¹ç•Œ |
| **ä¸Šä¸‹æ–‡ä¿ç•™** | é»˜è®¤é™„åŠ å‰ä¸€ä¸ªpairçš„å®Œæ•´å†…å®¹ |
| **Metadataæå–** | LLMåˆ†ä¸¤å±‚ï¼šsessionçº§ + pairçº§ |
| **Goalç”Ÿæˆ** | æ¯ä¸ªpairç‹¬ç«‹ç”Ÿæˆgoal.json |
| **Q1åˆ†æ** | æ¯ä¸ªpairç‹¬ç«‹è¿è¡ŒQ1ï¼Œç»“æœå­˜å…¥runs/<query_id>/ |

### ä¼˜åŠ¿

âœ… **å¯æ‰©å±•**ï¼šæ”¯æŒä»»æ„é•¿åº¦çš„å¯¹è¯
âœ… **ä¸Šä¸‹æ–‡æ„ŸçŸ¥**ï¼šä¿ç•™å¿…è¦çš„ä¾èµ–å…³ç³»
âœ… **ç‹¬ç«‹åˆ†æ**ï¼šæ¯ä¸ªpairå¯ç‹¬ç«‹è¿è¡ŒQ1
âœ… **å¯è¿½æº¯**ï¼šå®Œæ•´çš„metadataé“¾è·¯
âœ… **æ˜“æŸ¥è¯¢**ï¼šç»“æ„åŒ–çš„æ•°æ®ä¾¿äºç»Ÿè®¡åˆ†æ

### ä¸‹ä¸€æ­¥å®æ–½

1. âœ… æ•°æ®ç»“æ„å®šä¹‰å·²å®Œæˆï¼ˆ`types/cursor-chat/`ï¼‰
2. â³ å®ç°`tools/process_long_conversation.py`
3. â³ æµ‹è¯•10287è¡Œçš„spot-testæ–‡ä»¶
4. â³ ä¼˜åŒ–LLM promptæé«˜å‡†ç¡®æ€§
5. â³ æ·»åŠ æŸ¥è¯¢å’Œå¯è§†åŒ–å·¥å…·

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- `types/cursor-chat/session.ts` - Sessionæ•°æ®ç»“æ„
- `types/cursor-chat/pair.ts` - Query-Answer Pairæ•°æ®ç»“æ„
- `q1-input-goaljson.md` - Goal.jsonç”Ÿæˆæ–¹æ¡ˆ
- `tools/process_long_conversation.py` - ä¸»å¤„ç†è„šæœ¬ï¼ˆå¾…å®ç°ï¼‰
