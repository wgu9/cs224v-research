"""
å¿«é€Ÿæµ‹è¯•ï¼šéªŒè¯æ‰€æœ‰æ­¥éª¤éƒ½èƒ½æ­£å¸¸è¿è¡Œ
ä¸éœ€è¦ç”¨æˆ·äº¤äº’ï¼Œè‡ªåŠ¨è¿è¡Œæ‰€æœ‰æ­¥éª¤
"""

from pathlib import Path
from step1_load_data import load_task
from step2_init_guards import FourGuardMonitor
from step3_mock_agent import MockAgent
from step4_monitor_actions import ActionMonitor
from step5_evaluate import evaluate_scope, evaluate_resolved_mock


def main():
    """å¿«é€Ÿæµ‹è¯•æ‰€æœ‰æ­¥éª¤"""
    print("=" * 80)
    print("Q1 Quick Test - éªŒè¯æ‰€æœ‰æ­¥éª¤æ­£å¸¸è¿è¡Œ")
    print("=" * 80)

    DATA_FILE = Path(__file__).parent.parent / "data" / "swebench" / "verified.jsonl"

    try:
        # Step 1
        print("\nâœ“ Step 1: æ•°æ®åŠ è½½...")
        task = load_task(DATA_FILE, task_index=0)
        print(f"  Task: {task.instance_id}")

        # Step 2
        print("\nâœ“ Step 2: Four-Guardåˆå§‹åŒ–...")
        guard = FourGuardMonitor(task)
        summary = guard.get_summary()
        print(f"  Scope limit: {summary['scope_file_limit']} files")

        # Step 3
        print("\nâœ“ Step 3: Mock Agentæ‰§è¡Œ...")
        agent = MockAgent(task.problem_statement, task.repo)
        result = agent.execute()
        print(f"  Actions: {len(result['actions'])}")

        # Step 4
        print("\nâœ“ Step 4: å®æ—¶ç›‘æ§...")
        monitor = ActionMonitor(guard)
        monitoring_results = []

        for idx, action in enumerate(result['actions'], 1):
            guard.action_history.append(action)
            monitor_result = monitor.monitor_action(action, idx)
            monitoring_results.append(monitor_result)

        drift_rate = sum(1 for r in monitoring_results if r['drift_score'] >= 0.5) / len(monitoring_results)
        print(f"  Drift rate: {drift_rate*100:.1f}%")

        # Step 5-6
        print("\nâœ“ Step 5-6: äº‹åè¯„ä¼°...")
        part_c = task.get_part_c()

        resolved_result = evaluate_resolved_mock(
            result['patch'],
            part_c['fail_to_pass'],
            part_c['pass_to_pass']
        )

        scope_result = evaluate_scope(result['patch'], part_c['ground_truth_patch'])

        print(f"  Resolved: {resolved_result['resolved']}")
        print(f"  Scope Precision: {scope_result['scope_precision']:.2f}")
        print(f"  Scope Recall: {scope_result['scope_recall']:.2f}")

        # æ€»ç»“
        print("\n" + "=" * 80)
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("=" * 80)

        print("\nğŸ“Š æœ€ç»ˆç»“æœ:")
        print(f"   Task: {task.instance_id}")
        print(f"   Resolved: {resolved_result['resolved']} {'âœ…' if resolved_result['resolved'] else 'âŒ'}")
        print(f"   Drift Rate: {drift_rate*100:.1f}% {'âœ…' if drift_rate < 0.15 else 'âš ï¸'}")
        print(f"   Scope Precision: {scope_result['scope_precision']:.2f}")
        print(f"   Scope Recall: {scope_result['scope_recall']:.2f}")

        return True

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
