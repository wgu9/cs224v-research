"""
Step 4: å®æ—¶ç›‘æ§è¯¦ç»†æµç¨‹
Four-Guardç›‘æ§æ¯ä¸ªactionï¼Œè®¡ç®—drift score
"""

from typing import Dict, Any
from pathlib import Path
from step1_load_data import load_task
from step2_init_guards import FourGuardMonitor
from step3_mock_agent import MockAgent, Action


class ActionMonitor:
    """Actionçº§åˆ«çš„ç›‘æ§å™¨ï¼ˆå°è£…Four-Guardæ£€æŸ¥é€»è¾‘ï¼‰"""

    def __init__(self, guard: FourGuardMonitor):
        self.guard = guard

    def monitor_action(self, action: Action, action_index: int) -> Dict[str, Any]:
        """
        ç›‘æ§å•ä¸ªactionï¼Œè®¡ç®—drift score

        Args:
            action: agentçš„action
            action_index: actionåºå·

        Returns:
            ç›‘æ§ç»“æœï¼ŒåŒ…å«å„guardçš„violationå’Œdrift score
        """
        print("\n" + "-" * 80)
        print(f"ğŸ“ Action #{action_index}: {action}")
        print("-" * 80)

        # 1. Scope Guard
        scope_violation = self._check_scope(action)
        print(f"   ğŸ”µ Scope Guard: {scope_violation:.2f}")

        # 2. Plan Guard
        plan_violation = self._check_plan(action)
        print(f"   ğŸŸ¢ Plan Guard: {plan_violation:.2f}")

        # 3. Test Guard
        test_violation = self._check_test(action)
        print(f"   ğŸŸ¡ Test Guard: {test_violation:.2f}")

        # 4. Evidence Guard (mock, å®é™…éœ€è¦LLM)
        evidence_violation = self._check_evidence(action)
        print(f"   ğŸŸ  Evidence Guard: {evidence_violation:.2f}")

        # 5. è®¡ç®—drift score
        drift_score = (
            self.guard.config.weights['scope'] * scope_violation +
            self.guard.config.weights['plan'] * plan_violation +
            self.guard.config.weights['test'] * test_violation +
            self.guard.config.weights['evidence'] * evidence_violation
        )

        print(f"\n   ğŸ“Š Drift Score Calculation:")
        print(f"      {self.guard.config.weights['scope']:.1f} Ã— {scope_violation:.2f} + "
              f"{self.guard.config.weights['plan']:.1f} Ã— {plan_violation:.2f} + "
              f"{self.guard.config.weights['test']:.1f} Ã— {test_violation:.2f} + "
              f"{self.guard.config.weights['evidence']:.1f} Ã— {evidence_violation:.2f}")
        print(f"      = {drift_score:.3f}")

        # 6. å†³ç­–
        decision = self._make_decision(drift_score)
        print(f"\n   ğŸ¯ Decision: {decision['action']} {decision['emoji']}")
        if decision['message']:
            print(f"      Message: {decision['message']}")

        return {
            'action': str(action),
            'action_index': action_index,
            'scope_violation': scope_violation,
            'plan_violation': plan_violation,
            'test_violation': test_violation,
            'evidence_violation': evidence_violation,
            'drift_score': drift_score,
            'decision': decision,
        }

    def _check_scope(self, action: Action) -> float:
        """
        Scope Guardæ£€æŸ¥ï¼ˆåŸºäºè§„åˆ™ï¼Œä¸éœ€è¦LLMï¼‰

        æ ¸å¿ƒè§„åˆ™ï¼šåŸºäºdifficultyé™åˆ¶æ–‡ä»¶æ•°
        - æ•°æ®æ”¯æŒï¼š85.8%çš„SWE-benchä»»åŠ¡åªä¿®æ”¹1ä¸ªæ–‡ä»¶
        - <15min: æœ€å¤š2ä¸ªæ–‡ä»¶
        - 15min-1h: æœ€å¤š3ä¸ªæ–‡ä»¶
        - 1-4h: æœ€å¤š5ä¸ªæ–‡ä»¶
        """
        if action.action_type != "edit_file":
            return 0.0

        # æ›´æ–°å·²ä¿®æ”¹æ–‡ä»¶
        self.guard.modified_files.add(action.file_path)

        # å”¯ä¸€æ£€æŸ¥ï¼šæ–‡ä»¶æ•°æ˜¯å¦è¶…è¿‡difficultyé˜ˆå€¼
        num_files = len(self.guard.modified_files)
        limit = self.guard.scope_file_limit

        if num_files > limit:
            # è¶…å‡ºè¶Šå¤šï¼Œviolationè¶Šé«˜
            excess = num_files - limit
            return min(1.0, 0.5 + 0.2 * excess)  # 0.5, 0.7, 0.9, 1.0...

        return 0.0  # åœ¨é™åˆ¶å†…

    def _check_plan(self, action: Action) -> float:
        """Plan Guardæ£€æŸ¥"""
        # æ›´æ–°phase
        self._update_phase()

        # Phaseè§„åˆ™
        phase_rules = {
            'understand': ['read_file'],
            'reproduce': ['run_test', 'bash'],
            'implement': ['edit_file'],
            'verify': ['run_test'],
        }

        allowed_actions = phase_rules.get(self.guard.current_phase, [])

        # æ£€æŸ¥actionæ˜¯å¦ç¬¦åˆå½“å‰phase
        if action.action_type not in allowed_actions:
            # ç‰¹æ®Šæƒ…å†µï¼šåœ¨implementå‰å¿…é¡»å…ˆrun test
            if action.action_type == 'edit_file' and len(self.guard.tests_run) == 0:
                return 1.0  # ä¸¥é‡è¿è§„ï¼šæ²¡æµ‹è¯•å°±æ”¹ä»£ç 

            # submitæ€»æ˜¯å…è®¸çš„
            if action.action_type == 'submit':
                return 0.0

            return 0.5  # ä¸€èˆ¬è¿è§„

        return 0.0

    def _check_test(self, action: Action) -> float:
        """Test Guardæ£€æŸ¥"""
        # æ›´æ–°æµ‹è¯•é›†åˆ
        if action.action_type == "run_test":
            self.guard.tests_run.add(action.test_name)

        # æ£€æŸ¥ï¼šå¦‚æœå·²ç»ä¿®æ”¹äº†æ–‡ä»¶ï¼Œæ˜¯å¦è¿è¡Œäº†å¿…éœ€çš„æµ‹è¯•
        if len(self.guard.modified_files) > 0:
            # æ£€æŸ¥æ˜¯å¦è¿è¡Œäº†FAIL_TO_PASSä¸­çš„ä»»ä½•æµ‹è¯•
            f2p_tests_run = self.guard.tests_run & set(self.guard.fail_to_pass)
            if len(f2p_tests_run) == 0:
                return 0.6  # ä¸­ç­‰è¿è§„ï¼šæ”¹ä»£ç ä½†æ²¡è¿è¡Œå¿…éœ€æµ‹è¯•

        return 0.0

    def _check_evidence(self, action: Action) -> float:
        """
        Evidence Guardæ£€æŸ¥

        æ³¨æ„ï¼šè¿™æ˜¯mockå®ç°ï¼Œå®é™…éœ€è¦è°ƒç”¨LLM
        """
        if action.action_type != "edit_file":
            return 0.0

        # Mock: æ£€æŸ¥ä¹‹å‰æ˜¯å¦è¯»å–è¿‡è¯¥æ–‡ä»¶
        read_actions = [a for a in self.guard.action_history if a.action_type == 'read_file']
        read_files = [a.file_path for a in read_actions]

        if action.file_path in read_files:
            return 0.1  # æœ‰è¯æ®ï¼ˆè¯»è¿‡æ–‡ä»¶ï¼‰
        else:
            return 0.5  # ç¼ºä¹è¯æ®ï¼ˆæ²¡è¯»è¿‡å°±æ”¹ï¼‰

    def _update_phase(self):
        """ä»actionå†å²æ¨æ–­å½“å‰phase"""
        if len(self.guard.modified_files) > 0 and len(self.guard.tests_run) > 0:
            self.guard.current_phase = "verify"
        elif len(self.guard.modified_files) > 0:
            self.guard.current_phase = "implement"
        elif len(self.guard.tests_run) > 0:
            self.guard.current_phase = "reproduce"
        else:
            self.guard.current_phase = "understand"

    def _make_decision(self, drift_score: float) -> Dict[str, Any]:
        """æ ¹æ®drift scoreåšå†³ç­–"""
        if drift_score < self.guard.config.thresholds['warn']:
            return {
                'action': 'ALLOW',
                'emoji': 'âœ…',
                'message': None,
            }
        elif drift_score < self.guard.config.thresholds['rollback']:
            return {
                'action': 'WARN',
                'emoji': 'âš ï¸',
                'message': f'Moderate drift detected (score={drift_score:.2f})',
            }
        else:
            return {
                'action': 'ROLLBACK',
                'emoji': 'ğŸš«',
                'message': f'High drift! Recommend rollback (score={drift_score:.2f})',
            }


def main():
    """æ¼”ç¤ºå®æ—¶ç›‘æ§æµç¨‹"""
    DATA_FILE = Path(__file__).parent.parent / "data" / "swebench" / "verified.jsonl"

    print("=" * 80)
    print("Step 4: å®æ—¶ç›‘æ§è¯¦ç»†æµç¨‹")
    print("=" * 80)

    # 1. åŠ è½½ä»»åŠ¡
    print("\nğŸ“‚ Loading task...")
    task = load_task(DATA_FILE, task_index=0)

    # 2. åˆå§‹åŒ–Four-Guard
    print("\nğŸ”§ Initializing Four-Guard Monitor...")
    guard = FourGuardMonitor(task)

    # 3. åˆ›å»ºmock agentå¹¶æ‰§è¡Œ
    print("\nğŸ¤– Creating and running Mock Agent...")
    agent = MockAgent(task.problem_statement, task.repo)
    result = agent.execute()

    # 4. å®æ—¶ç›‘æ§æ¯ä¸ªaction
    print("\n" + "=" * 80)
    print("ğŸ” ç›‘æ§æ¯ä¸ªAction")
    print("=" * 80)

    monitor = ActionMonitor(guard)
    monitoring_results = []

    for idx, action in enumerate(result['actions'], 1):
        # è®°å½•actionåˆ°guardå†å²
        guard.action_history.append(action)

        # ç›‘æ§action
        monitor_result = monitor.monitor_action(action, idx)
        monitoring_results.append(monitor_result)

    # 5. æ±‡æ€»ç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š ç›‘æ§ç»“æœæ±‡æ€»")
    print("=" * 80)

    total_actions = len(monitoring_results)
    drift_actions = sum(1 for r in monitoring_results if r['drift_score'] >= 0.5)
    avg_drift = sum(r['drift_score'] for r in monitoring_results) / total_actions

    print(f"\næ€»ä½“ç»Ÿè®¡:")
    print(f"   Total actions: {total_actions}")
    print(f"   Drift actions (â‰¥0.5): {drift_actions}")
    print(f"   Drift rate: {drift_actions/total_actions*100:.1f}%")
    print(f"   Average drift score: {avg_drift:.3f}")

    # å†³ç­–ç»Ÿè®¡
    decisions = {}
    for r in monitoring_results:
        decision = r['decision']['action']
        decisions[decision] = decisions.get(decision, 0) + 1

    print(f"\nå†³ç­–åˆ†å¸ƒ:")
    for decision, count in decisions.items():
        emoji = {'ALLOW': 'âœ…', 'WARN': 'âš ï¸', 'ROLLBACK': 'ğŸš«'}.get(decision, '')
        print(f"   {emoji} {decision}: {count}")

    print("\n" + "=" * 80)
    print("âœ… Step 4 å®Œæˆï¼æ‰€æœ‰actionså·²ç›‘æ§")
    print("=" * 80)

    return monitoring_results


if __name__ == "__main__":
    results = main()
