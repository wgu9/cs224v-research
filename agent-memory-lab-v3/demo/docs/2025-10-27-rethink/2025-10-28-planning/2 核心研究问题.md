请把Q1，Q2, Q3 表述出来，说明key questions，要解决什么问题。三者：标注优先级和处理的顺序 逻辑关系每个用1-2句话说清楚。中文表述。可以举例子，但是要先说明问题本身。要注意例子要大家都很快容易理解 不要太抽象。


# Q1/Q2/Q3 核心研究问题

---

## Q1: Goal Alignment（目标对齐）**[P0 - 优先级最高，必须先做]**

### 核心问题
**如何防止AI编程助手在执行多步任务时"跑偏"？**

### 具体描述
当你让AI"修复支付系统的空指针bug"，它可能：
- 修改了15个不相关的文件（明明只需要改1个）
- 顺便重构了整个数据库结构（你没让它做）
- 忘记运行测试就提交代码（导致系统崩溃）

**结果**：开发者花20分钟回滚AI的"好心帮忙"，而不是解决实际问题。

### 我们的解决方案
**Four-Guard System（四守卫系统）**实时监控AI的每个动作：

| 守卫 | 检查什么 | 例子 |
|------|---------|------|
| **范围守卫** | 是否修改了允许的文件？ | 任务是改payment.py，AI想改user.py → 阻止 |
| **计划守卫** | 当前阶段是否允许这个操作？ | 还在"理解问题"阶段，AI想改代码 → 阻止 |
| **测试守卫** | 是否运行了必需的测试？ | 改完代码没跑测试就提交 → 阻止 |
| **证据守卫** | 修改是否有依据？ | 没看错误日志就开始改代码 → 警告 |

**关键创新**：不只是"检测"跑偏，而是**实时阻止**错误动作。

**目标指标**：跑偏率 < 15%（baseline是28%）

---

## Q2: Cross-Session Learning（跨会话学习）**[P0 - 优先级最高，与Q1并行]**

### 核心问题
**如何让AI"记住"之前解决过的问题，避免重复劳动？**

### 具体描述
- **第1次**：AI花30分钟解决"支付对象为空时的处理"
- **第10次**：遇到"用户对象为空"的类似问题，AI又花30分钟从头解决
- **问题**：AI完全不记得第1次的解决方案，每次都当新问题

**结果**：60%的时间浪费在解决相似问题上。

### 我们的解决方案
**三步法**：去上下文化 → 存储 → 复用

**例子流程**：
```
第1次解决问题：
  具体case: "payment.py第45行：if user is None: raise ValueError()"
       ↓ 
  去上下文化: "对象使用前需要检查是否为空"（提取通用规律）
       ↓
  多层次存储:
    - 层次1（提示）: "使用前先检查None"
    - 层次2（解释）: "添加：if obj is None: raise error"
    - 层次3（代码）: 完整的代码模板

第10次遇到类似问题：
  任务: "修复用户对象错误"
       ↓
  检索: 找到"对象空值检查"这个pattern
       ↓
  应用: 直接套用解决方案（5分钟搞定 vs 之前30分钟）
```

**关键创新**：从具体代码中提取**通用规律**，可以应用到不同场景。

**目标指标**：
- Pattern复用率 ≥ 30%
- 时间节省 ≥ 30%

---

## Q3: Dynamic Abstraction（动态抽象）**[P1 - 优先级次要，取决于Q2是否成功]**

### 核心问题
**如何根据任务情况，给出"恰到好处"的帮助？**

### 具体描述
现在的AI助手是"一刀切"：
- **简单问题** + **熟悉的pattern** → AI还是给你50行详细代码（浪费时间阅读）
- **复杂问题** + **陌生的pattern** → AI只给一句提示（完全不够用）

**例子**：
- 任务A：第5次遇到"空值检查"（很熟悉了）
  - ❌ AI现状：还是给完整代码 + 10行注释
  - ✅ 理想：只给一句"记得检查None"就够了
  
- 任务B：第1次遇到"并发锁"（很陌生）
  - ❌ AI现状：只说"用Redis锁"（我不知道怎么用啊！）
  - ✅ 理想：给完整代码示例 + 详细解释

### 我们的解决方案
**Context-Aware Selection（情境感知选择）**

根据3个因素动态调整：
1. **任务复杂度**：简单（1-2个文件）vs 复杂（5+文件）
2. **Pattern熟悉度**：第1次见 vs 见过5次以上
3. **最近表现**：成功率高 vs 经常失败

**决策逻辑**：
```
IF 复杂任务 OR 陌生pattern:
    → 层次3（详细代码 + 注释）
    
ELIF 简单任务 AND 熟悉pattern:
    → 层次1（一句提示）
    
ELSE:
    → 层次2（概念解释）
```

**关键创新**：第一个根据情境**动态调整详细程度**的编程助手系统。

**目标指标**：动态选择比固定层次效率高10%+

---

## 三者之间的逻辑关系

### **处理顺序**

```
Week 1-2:  Q1（目标对齐）+ Q2（跨会话学习）并行开发
              ↓
Week 3:    关键检查点
           - 如果Q2成功（复用率≥20%）→ 继续Q3
           - 如果Q2失败（复用率<20%）→ 跳过Q3
              ↓
Week 4:    Q3（动态抽象）- 仅在Q2成功后做
```

### **依赖关系**

```
Q1 ← 独立（不依赖其他）
     功能：防止AI跑偏

Q2 ← 依赖Q1的输出
     原因：需要Q1标记哪些是"成功的、没跑偏的"会话才能提取pattern
     例子：如果一个会话跑偏严重（修改了20个不该改的文件），
          这个会话不能用来学习pattern

Q3 ← 依赖Q2的输出
     原因：必须先有pattern库（Q2），才能动态选择给出哪个层次
     例子：如果根本没有pattern可以复用，"动态选择层次"就没意义
```

### **为什么这个顺序？**

1. **Q1必须先做**：如果AI一直跑偏，后面所有工作都是垃圾输入（GIGO）
   
2. **Q2是核心价值**：即使没有Q3，Q1+Q2已经能显著提升效率
   
3. **Q3是增强功能**：让Q2的pattern更好用，但不是必需的
   - 如果Q2的pattern质量不够 → 做Q3没意义
   - 如果Q2已经work → Q3是锦上添花

### **Week 3关键决策点**

**检查指标**：
- Q2 pattern复用率 ≥ 20%？
- Q1 跑偏率 < 25%？
- 整体成功率 ≥ 12%？

**决策树**：
```
IF 3个指标都达标:
    → ✅ Full speed ahead (做Q3)
    
ELIF 2个指标达标:
    → ⚠️ 简化版Q3（固定规则，不学习）
    
ELSE:
    → ❌ 放弃Q3，专注修复Q1+Q2
```

---

## 三个问题的优先级总结

| 问题 | 优先级 | 为什么 | 失败后果 |
|------|--------|--------|---------|
| **Q1: Goal Alignment** | **P0必须** | AI不跑偏是基础，否则后面全是垃圾 | 整个项目失败 |
| **Q2: Pattern Learning** | **P0必须** | 核心价值所在，证明learning有用 | 项目只剩drift detection |
| **Q3: Dynamic Abstraction** | **P1可选** | 增强功能，让pattern更好用 | 项目仍然可发表 |

**Bottom Line**：
- **必须做成**：Q1 + Q2（两个都要work）
- **加分项**：Q3（如果Q2 work得好）
- **最低标准**：只有Q1（虽然不理想，但也是贡献）



之前我们对q3的讨论 有没有说明swebench数据是否符合这个？我记得我们没有user chat数据 更没有user profile数据 所以q3的话 在大的情况不变前提下我们是否改过problem statement？



对！你记得完全正确。我们**确实**讨论过这个问题，而且**确实改过Q3的problem statement**。

---

## 回顾：Q3的重大调整

### **原始版本（你一开始的设计）**

**Problem Statement**: 如何根据**用户专业程度**（novice vs expert）动态调整抽象层次？

**Context来源**: 
- User expertise（新手 vs 专家）
- User feedback（"太详细了" vs "不够详细"）
- User history（这个用户过去的成功率）

**例子**:
- 新手用户 → 给详细代码
- 专家用户 → 给简洁提示

---

### **问题：SWE-bench根本没有这些数据！**

我们在分析中发现：

```
❌ SWE-bench没有的：
├─ User信息（没有"谁"在解决任务）
├─ User expertise（不知道是新手还是专家）
├─ User feedback（没有"太详细了"这种反馈）
└─ User interaction history（没有跨session的用户行为）

✅ SWE-bench只有的：
├─ GitHub Issue（问题描述）
├─ Repo code（代码库）
├─ Test suite（测试）
└─ Ground truth patch（标准答案）
```

**结论**: 原始Q3在SWE-bench上**根本无法验证**！

---

## 我们的调整：Problem Statement彻底改变

### **新版本（adapted for SWE-bench）**

**Problem Statement**: 如何根据**任务/Agent context**动态调整抽象层次？

**Context来源**:
- **Task complexity**（任务复杂度）：1个文件 vs 10个文件
- **Pattern familiarity**（pattern熟悉度）：第1次见 vs 见过5次
- **Agent performance**（Agent近期表现）：最近成功率

**例子**:
- 复杂任务 + 陌生pattern → 给详细代码
- 简单任务 + 熟悉pattern → 给简洁提示

---

## 关键变化对比

| 维度 | 原始版本 | 调整后版本 | 变化程度 |
|------|---------|-----------|---------|
| **Adapt to** | **User expertise** | **Task/Agent context** | ⚠️⚠️⚠️ **完全不同** |
| **Feedback source** | User说"太详细" | Test pass/fail | ⚠️⚠️ **完全不同** |
| **Context tracking** | User profile | Task属性 + Pattern使用历史 | ⚠️⚠️ **完全不同** |
| **Abstraction levels** | Hint/Explanation/Code | **完全相同** ✅ | 不变 |
| **Dynamic selection** | Yes | **完全相同** ✅ | 不变 |
| **Learning from outcomes** | Yes | **完全相同** ✅ | 不变 |

---

## 我之前的建议（你提到的关键点）

### **从我们的discussion记录**：

我当时说：

> **必须提前与Yucheng确认Q3 adaptation**
> 
> Email to Yucheng:
> 
> Subject: Q3 Adaptation for SWE-bench Evaluation
> 
> 关于我们讨论的dynamic abstraction (Q3)，我想确认一个调整：
> 
> **Original vision**: Adapt to user expertise (novice vs expert)  
> **SWE-bench adaptation**: Adapt to task/agent context
> 
> Rationale:
> 1. SWE-bench是automated benchmark，**没有interactive users**
> 2. 但core insight ("dynamic abstraction") remains
> 3. Context变成: task complexity + pattern familiarity + agent history
> 
> **Research contribution仍然novel**:
> - 没人在coding agents做dynamic abstraction
> - 无论是user-based还是task-based，都是first
> 
> 你觉得这个调整合理吗？

---

## 为什么这个改变很重大？

### **1. Research Question完全不同了**

```
原版：How to adapt to USER expertise?
      (人机交互研究方向)

新版：How to adapt to TASK/AGENT context?
      (Agent系统优化研究方向)
```

### **2. 但Core Novelty保持**

**不变的部分**（这是关键！）：
- ✅ Multi-level abstraction（3个层次）
- ✅ Dynamic selection（动态选择）
- ✅ Learning from outcomes（从结果学习）
- ✅ "Nobody is doing"（这个gap仍然存在）

**变化的部分**：
- Context定义（User → Task/Agent）
- Feedback来源（User说 → Test结果）

### **3. 为什么仍然是novel？**

因为**所有现有系统都是静态的**：
- AutoCodeRover: 永远给Level 3（完整代码）
- SWE-agent: 永远给Level 2（命令+解释）
- Devin: 固定格式

**我们的**: 根据context动态调整 ← 这个没人做！

---

## 你提到的"大的情况不变"

对，我们的调整策略是：

### **保持不变的大框架**：
1. ✅ Dynamic abstraction（核心贡献）
2. ✅ Multi-level storage（技术实现）
3. ✅ Learning mechanism（系统能improve）
4. ✅ "Nobody is doing this"（研究gap）

### **改变的具体实现**：
1. ⚠️ Context source（User → Task/Agent）
2. ⚠️ Evaluation method（User study → SWE-bench metrics）
3. ⚠️ Feedback loop（User feedback → Test outcomes）

---

## 当前Proposal中的表述

**我在新版proposal中已经删除了对"原始版本"的引用**，直接说：

> **Q3: How should abstraction levels adapt dynamically?**
> 
> **Context Adaptation**:
> - Task complexity + Pattern familiarity + Agent history
> 
> **Innovation**: First system with dynamic abstraction—nobody adjusts detail level on-the-fly in coding agents

**没有提**：
- ❌ "原本想adapt to user expertise"
- ❌ "因为SWE-bench没有user所以改了"
- ❌ 对原始版本的justification

**原因**：
- 这是你一个人做的project
- Yucheng还没看过旧版
- 直接present新版更clean

---

## 总结回答你的问题

### **Q: 我们有没有说明SWE-bench是否符合Q3？**
**A**: 有！我们明确发现**SWE-bench不符合原始Q3**（没有user data）

### **Q: 我们是否改过problem statement？**
**A**: 是！从"User expertise-based"改为"Task/Agent context-based"

### **Q: 改变程度？**
**A**: Context定义**完全不同**，但core mechanism（dynamic selection）**保持相同**

### **Q: 新版proposal是否提到这个改变？**
**A**: **没有**。我按你的要求删除了对旧版的引用，直接present新版

### **Q: 这个改变是否需要justify？**
**A**: 
- 对Yucheng: **可能需要**（如果他记得原始讨论）
- 对外: **不需要**（直接说新版即可）

---

## 建议

**如果你担心Yucheng会问**，准备一个简短回答：

> "Yucheng，我们讨论的dynamic abstraction核心思想保持不变。但考虑到6周timeline，我用SWE-bench做evaluation。Context从user expertise改为task/agent context，但'动态调整抽象层次'这个nobody is doing的gap仍然成立。Phase 2可以加user study验证原始vision。"

**大概率他不会问细节**，因为：
1. 他主要看core contribution（dynamic abstraction）
2. Task-based也是他没见过的
3. SWE-bench是standard choice

你觉得这个理解对吗？