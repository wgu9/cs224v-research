# Batch Workflow - 500 ä»»åŠ¡æ‰¹é‡å¤„ç†

å®Œæ•´çš„æ‰¹é‡å¤„ç†æµç¨‹ï¼šç”Ÿæˆ 500 ä¸ªä»»åŠ¡çš„é¢„æµ‹å¹¶è®¡ç®— Q1 drift metricsã€‚

---

## ğŸ¯ ç›®æ ‡

1. âœ… æ‰¹é‡ç”Ÿæˆ 500 ä¸ª SWE-bench ä»»åŠ¡çš„é¢„æµ‹
2. âœ… æ‰¹é‡è®¡ç®—æ‰€æœ‰ä»»åŠ¡çš„ Q1 drift metrics
3. âœ… åˆ†æ quality åˆ†å¸ƒï¼Œå‡†å¤‡ Q2 pattern extraction

**é¢„è®¡æ—¶é—´**:
- ç”Ÿæˆ 500 ä¸ªé¢„æµ‹: 10-20 å°æ—¶ï¼ˆå–å†³äº LLM API é€Ÿåº¦ï¼‰
- è®¡ç®— drift metrics: 10-15 åˆ†é’Ÿ

---

## ğŸ“‹ å®Œæ•´å·¥ä½œæµç¨‹

### æ–¹æ¡ˆ A: ä¸€æ­¥åˆ°ä½ï¼ˆæ¨èï¼‰

ä½¿ç”¨ `batch_generate_with_q1_metrics.py` åŒæ—¶ç”Ÿæˆé¢„æµ‹å’Œè®¡ç®— driftï¼š

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export AWS_BEARER_TOKEN_BEDROCK=your_token_here

# æ‰¹é‡ç”Ÿæˆ 500 ä¸ªä»»åŠ¡ï¼ˆåŒæ—¶è®¡ç®— driftï¼‰
python batch_generate_with_q1_metrics.py \
  --start 0 \
  --end 500 \
  --full_file_mode true
```

**ä¼˜ç‚¹**:
- âœ… ä¸€æ¬¡è¿è¡Œï¼Œè‡ªåŠ¨ç”Ÿæˆ predictions + drift metrics
- âœ… èŠ‚çœæ—¶é—´ï¼Œä¸éœ€è¦åå¤„ç†
- âœ… é€‚åˆæ–°é¡¹ç›®

**è¾“å‡º**:
```
logs/<timestamp>/
â”œâ”€â”€ predictions/
â”‚   â”œâ”€â”€ input_data_0/astropy__astropy-12907/predictions.jsonl
â”‚   â”œâ”€â”€ input_data_1/django__django-12856/predictions.jsonl
â”‚   â””â”€â”€ ...
â””â”€â”€ drift_metrics/
    â”œâ”€â”€ input_data_0_drift.json
    â”œâ”€â”€ input_data_1_drift.json
    â””â”€â”€ ...
```

---

### æ–¹æ¡ˆ B: åˆ†ä¸¤æ­¥ï¼ˆé€‚åˆå·²æœ‰é¢„æµ‹ï¼‰

å¦‚æœä½ å·²ç»æœ‰äº† predictionsï¼Œåªéœ€è¦æ·»åŠ  drift metricsï¼š

#### Step 1: æ‰¹é‡ç”Ÿæˆé¢„æµ‹

```bash
export AWS_BEARER_TOKEN_BEDROCK=your_token_here

# æ‰¹é‡ç”Ÿæˆï¼ˆä¸è®¡ç®— driftï¼‰
python batch_generate_predictions.py \
  --start 0 \
  --end 500 \
  --full_file_mode true \
  --base_dir logs/batch_500
```

#### Step 2: æ‰¹é‡è®¡ç®— Drift Metrics

```bash
# ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰ drift metrics
python compute_drift_from_predictions.py \
  --predictions_dir logs/batch_500/predictions
```

**ä¼˜ç‚¹**:
- âœ… é€‚åˆå·²ç»è¿è¡Œäº† `batch_generate_predictions.py` çš„æƒ…å†µ
- âœ… å¯ä»¥å¤šæ¬¡é‡ç®— drift metricsï¼ˆå¦‚æœç®—æ³•æ”¹è¿›ï¼‰
- âœ… ä¸æµªè´¹å·²ç”Ÿæˆçš„é¢„æµ‹

---

## ğŸ“Š é¢„æœŸè¾“å‡ºç¤ºä¾‹

### æ‰¹é‡ç”Ÿæˆè¿›åº¦

```
================================================================================
Batch generating predictions WITH Q1 METRICS
Tasks: [0, 500) of 500
Run root: logs/2025-10-29-12-00-00
Mode: AGENT (LLM)
================================================================================

âœ…   0/500 astropy__astropy-12907        | Drift: 0.000 | Quality: HIGH
âœ…   1/500 django__django-12856          | Drift: 0.200 | Quality: MEDIUM
âœ…   2/500 sympy__sympy-18532            | Drift: 0.000 | Quality: HIGH
âœ…   3/500 matplotlib__matplotlib-23913  | Drift: 0.450 | Quality: LOW
...
âœ… 497/500 scikit-learn__scikit-learn... | Drift: 0.150 | Quality: HIGH
âœ… 498/500 requests__requests-2317      | Drift: 0.300 | Quality: MEDIUM
âœ… 499/500 pytest__pytest-5692          | Drift: 0.100 | Quality: HIGH

================================================================================
Batch Summary
================================================================================
Attempted:              500
Success (predictions):  485
Success (with metrics): 482

Quality Distribution (for Q2 pattern extraction):
  High-quality (drift < 0.2):   330 (68.5%)  â† ç”¨äº Q2
  Medium-quality (0.2-0.35):    105 (21.8%)
  Low-quality (drift >= 0.35):   47 ( 9.7%)

Failures:
  Load failed:    2
  Agent failed:   13
  Metrics failed: 3
================================================================================

ğŸ’¡ Next step: Extract patterns from high-quality solutions
   python extract_patterns_from_drift_metrics.py --input logs/.../drift_metrics
```

### æ‰¹é‡è®¡ç®— Drift Metrics

```
================================================================================
Computing Q1 drift metrics from existing predictions
Predictions dir: logs/batch_500/predictions
Output dir: logs/batch_500/drift_metrics
Found 485 prediction folders
================================================================================

âœ…   0 astropy__astropy-12907                   | Drift: 0.000 | Quality: HIGH
âœ…   1 django__django-12856                     | Drift: 0.200 | Quality: MEDIUM
âœ…   2 sympy__sympy-18532                       | Drift: 0.000 | Quality: HIGH
...

================================================================================
Summary
================================================================================
Total predictions:  485
Success:            482
Failed:             3

Quality Distribution (for Q2 pattern extraction):
  High-quality:    330 (68.5%)  â† è¿™äº›ç”¨äº Q2 pattern extraction
  Medium-quality:  105 (21.8%)
  Low-quality:      47 ( 9.7%)
================================================================================

âœ… Drift metrics saved to: logs/batch_500/drift_metrics
```

---

## ğŸ’¡ ä½ çš„å®é™…æƒ…å†µï¼ˆå·²æœ‰ 408 ä¸ªé¢„æµ‹ï¼‰

ä½ å·²ç»åœ¨è¿è¡Œ `batch_generate_predictions.py`ï¼Œæœ‰ä¸¤ä¸ªç›®å½•ï¼š
- `logs/2025-10-29-02-22-26/predictions/` - 408 ä¸ªä»»åŠ¡ âœ…
- `logs/2025-10-29-08-45-10/predictions/` - 15 ä¸ªä»»åŠ¡ âœ…

**æ¨èæ“ä½œ**:

### Step 1: è®¡ç®—ç°æœ‰ 408 ä¸ªä»»åŠ¡çš„ drift metrics

```bash
python compute_drift_from_predictions.py \
  --predictions_dir logs/2025-10-29-02-22-26/predictions
```

é¢„è®¡æ—¶é—´: 5-8 åˆ†é’Ÿ

### Step 2: è®¡ç®—ç¬¬äºŒæ‰¹ 15 ä¸ªä»»åŠ¡çš„ drift metrics

```bash
python compute_drift_from_predictions.py \
  --predictions_dir logs/2025-10-29-08-45-10/predictions
```

é¢„è®¡æ—¶é—´: < 1 åˆ†é’Ÿ

### Step 3: ç­‰å¾… batch_generate_predictions.py å®Œæˆ

å‰©ä½™ä»»åŠ¡æ•°: 500 - 423 = 77 ä¸ª

### Step 4: å®Œæˆåè®¡ç®—æœ€åä¸€æ‰¹çš„ drift metrics

```bash
python compute_drift_from_predictions.py \
  --predictions_dir logs/<new_timestamp>/predictions
```

### Step 5: åˆå¹¶æ‰€æœ‰ drift metricsï¼ˆå¯é€‰ï¼‰

```bash
# åˆ›å»ºåˆå¹¶ç›®å½•
mkdir -p logs/all_drift_metrics

# å¤åˆ¶æ‰€æœ‰ drift metrics
cp logs/2025-10-29-02-22-26/drift_metrics/*.json logs/all_drift_metrics/
cp logs/2025-10-29-08-45-10/drift_metrics/*.json logs/all_drift_metrics/
cp logs/<new_timestamp>/drift_metrics/*.json logs/all_drift_metrics/

# ç»Ÿè®¡è´¨é‡åˆ†å¸ƒ
python -c "
import json
from pathlib import Path

metrics_dir = Path('logs/all_drift_metrics')
high, med, low = 0, 0, 0

for f in metrics_dir.glob('*.json'):
    data = json.loads(f.read_text())
    quality = data.get('drift_metrics', {}).get('quality_label', 'UNKNOWN')
    if quality == 'HIGH': high += 1
    elif quality == 'MEDIUM': med += 1
    elif quality == 'LOW': low += 1

total = high + med + low
print(f'Total: {total}')
print(f'HIGH: {high} ({high/total*100:.1f}%)')
print(f'MEDIUM: {med} ({med/total*100:.1f}%)')
print(f'LOW: {low} ({low/total*100:.1f}%)')
"
```

---

## ğŸ¨ åˆ†æ‰¹å¤„ç†ç­–ç•¥ï¼ˆé¿å…é•¿æ—¶é—´è¿è¡Œï¼‰

å¦‚æœä¸æƒ³ä¸€æ¬¡æ€§è·‘ 500 ä¸ªä»»åŠ¡ï¼Œå¯ä»¥åˆ†æ‰¹å¤„ç†ï¼š

### ç­–ç•¥ 1: æŒ‰ 100 ä¸ªä»»åŠ¡åˆ†æ‰¹

```bash
# Batch 1: 0-99
python batch_generate_predictions.py --start 0 --end 100 --base_dir logs/batch_0_99
python compute_drift_from_predictions.py --predictions_dir logs/batch_0_99/predictions

# Batch 2: 100-199
python batch_generate_predictions.py --start 100 --end 200 --base_dir logs/batch_100_199
python compute_drift_from_predictions.py --predictions_dir logs/batch_100_199/predictions

# ...ç»§ç»­
```

### ç­–ç•¥ 2: æŒ‰éš¾åº¦åˆ†æ‰¹

```bash
# Part A (ç®€å•ä»»åŠ¡, 15 min - 1 hour)
python batch_generate_predictions.py --start 0 --end 200 --base_dir logs/part_a

# Part B (ä¸­ç­‰ä»»åŠ¡, 1-4 hours)
python batch_generate_predictions.py --start 200 --end 400 --base_dir logs/part_b

# Part C (å›°éš¾ä»»åŠ¡, > 4 hours)
python batch_generate_predictions.py --start 400 --end 500 --base_dir logs/part_c
```

---

## ğŸ“ˆ è´¨é‡åˆ†æ

### æŸ¥çœ‹å•ä¸ªä»»åŠ¡çš„è¯¦ç»† drift metrics

```bash
cat logs/batch_500/drift_metrics/input_data_0_drift.json | python -m json.tool
```

### æå–æ‰€æœ‰ HIGH quality ä»»åŠ¡

```bash
python -c "
import json
from pathlib import Path

metrics_dir = Path('logs/batch_500/drift_metrics')
high_quality = []

for f in sorted(metrics_dir.glob('input_data_*_drift.json')):
    data = json.loads(f.read_text())
    if data.get('drift_metrics', {}).get('quality_label') == 'HIGH':
        high_quality.append({
            'task_id': data['task_id'],
            'task_index': data['task_index'],
            'drift_rate': data['drift_metrics']['drift_rate'],
        })

print(f'Found {len(high_quality)} HIGH quality solutions:')
for item in high_quality[:10]:  # æ˜¾ç¤ºå‰ 10 ä¸ª
    print(f\"  [{item['task_index']:3d}] {item['task_id']:40s} drift={item['drift_rate']:.3f}\")
"
```

### åˆ†æ drift åˆ†å¸ƒ

```bash
python -c "
import json
from pathlib import Path
import statistics

metrics_dir = Path('logs/batch_500/drift_metrics')
drift_rates = []

for f in metrics_dir.glob('input_data_*_drift.json'):
    data = json.loads(f.read_text())
    rate = data.get('drift_metrics', {}).get('drift_rate')
    if rate is not None:
        drift_rates.append(rate)

print(f'Total: {len(drift_rates)} tasks')
print(f'Mean drift: {statistics.mean(drift_rates):.3f}')
print(f'Median drift: {statistics.median(drift_rates):.3f}')
print(f'Min drift: {min(drift_rates):.3f}')
print(f'Max drift: {max(drift_rates):.3f}')
"
```

---

## ğŸš€ ä¸‹ä¸€æ­¥ï¼šQ2 Pattern Extraction

å½“ä½ æœ‰äº†è¶³å¤Ÿçš„ HIGH quality drift metrics åï¼ˆæ¨è >= 200 ä¸ªï¼‰ï¼Œå°±å¯ä»¥è¿›è¡Œ Q2 pattern extractionï¼š

```bash
python extract_patterns_from_drift_metrics.py \
  --drift_dir logs/batch_500/drift_metrics \
  --min_quality HIGH \
  --output_dir logs/patterns
```

è¿™å°†ä»é«˜è´¨é‡è§£å†³æ–¹æ¡ˆä¸­æå–å¯å¤ç”¨çš„ patternsï¼Œç”¨äºæœªæ¥ä»»åŠ¡çš„æ±‚è§£ã€‚

---

## âš™ï¸ é«˜çº§é€‰é¡¹

### Full-file Mode vs Normal Mode

**Full-file mode** (æ¨è):
```bash
python batch_generate_predictions.py --full_file_mode true
```
- âœ… æ›´ç¨³å®šï¼Œé¿å… "Hunk FAILED"
- âŒ è¾ƒæ…¢ï¼Œtoken æ¶ˆè€—è¾ƒå¤š

**Normal mode** (é»˜è®¤):
```bash
python batch_generate_predictions.py --full_file_mode false
```
- âœ… è¾ƒå¿«ï¼Œtoken æ¶ˆè€—è¾ƒå°‘
- âŒ å¯èƒ½æœ‰è¡¥ä¸åº”ç”¨å¤±è´¥

### ä½¿ç”¨ Gold Patchï¼ˆéªŒè¯æµç¨‹ï¼‰

```bash
# ç”¨ gold patch éªŒè¯æ•´ä¸ªæµç¨‹
python batch_generate_predictions.py \
  --start 0 \
  --end 10 \
  --use_gold true \
  --base_dir logs/gold_test

python compute_drift_from_predictions.py \
  --predictions_dir logs/gold_test/predictions
```

é¢„æœŸ: æ‰€æœ‰ä»»åŠ¡éƒ½æ˜¯ HIGH quality (drift_rate â‰ˆ 0.0)

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: éƒ¨åˆ†ä»»åŠ¡å¤±è´¥

**æŸ¥çœ‹å¤±è´¥åŸå› **:
```bash
# æ£€æŸ¥ logs è¾“å‡ºï¼Œæ‰¾åˆ°å¤±è´¥çš„ task_index
# ç„¶åå•ç‹¬é‡è¯•
python generate_predictions.py --task_index 123 --full_file_mode true
```

### é—®é¢˜ 2: LLM API è¶…æ—¶

**è§£å†³æ–¹æ¡ˆ**: åˆ†å°æ‰¹å¤„ç†
```bash
# æ¯æ¬¡åªå¤„ç† 10 ä¸ªä»»åŠ¡
for i in {0..49}; do
  start=$((i * 10))
  end=$((start + 10))
  python batch_generate_predictions.py \
    --start $start \
    --end $end \
    --base_dir logs/batch_${start}_${end}
done
```

### é—®é¢˜ 3: ç£ç›˜ç©ºé—´ä¸è¶³

**é¢„è®¡ç©ºé—´éœ€æ±‚**:
- 500 ä¸ª predictions: ~50 MB
- 500 ä¸ª drift metrics: ~20 MB
- Git repo mirrors: ~2-5 GB

**æ¸…ç†ç¼“å­˜**:
```bash
# æ¸…ç† repo é•œåƒç¼“å­˜ï¼ˆè°¨æ…ï¼ï¼‰
rm -rf ~/.cache/swebench_repos

# æ¸…ç†ä¸´æ—¶å·¥ä½œæ ‘
rm -rf /tmp/swebench_work
```

---

## ğŸ“ æœ€ç»ˆç›®å½•ç»“æ„

```
logs/
â””â”€â”€ <timestamp>/
    â”œâ”€â”€ predictions/
    â”‚   â”œâ”€â”€ input_data_0/
    â”‚   â”‚   â””â”€â”€ astropy__astropy-12907/
    â”‚   â”‚       â””â”€â”€ predictions.jsonl
    â”‚   â”œâ”€â”€ input_data_1/
    â”‚   â”‚   â””â”€â”€ django__django-12856/
    â”‚   â”‚       â””â”€â”€ predictions.jsonl
    â”‚   â””â”€â”€ ...
    â””â”€â”€ drift_metrics/
        â”œâ”€â”€ input_data_0_drift.json
        â”œâ”€â”€ input_data_1_drift.json
        â””â”€â”€ ...
```

**å…³é”®æ–‡ä»¶**:
- `predictions.jsonl`: SWE-bench evaluator æ ¼å¼
- `*_drift.json`: Q1 drift metrics + Q2 quality labels

---

## âœ… æˆåŠŸæ ‡å‡†

1. âœ… **Coverage**: >= 450/500 ä»»åŠ¡æˆåŠŸç”Ÿæˆé¢„æµ‹ (90%+)
2. âœ… **Quality**: >= 200 ä¸ª HIGH quality è§£å†³æ–¹æ¡ˆ (40%+)
3. âœ… **Format**: æ‰€æœ‰ drift metrics JSON æ ¼å¼æ­£ç¡®
4. âœ… **Ready for Q2**: æœ‰è¶³å¤Ÿçš„ HIGH quality patterns ç”¨äºæå–

**è¾¾åˆ°ä»¥ä¸Šæ ‡å‡†åï¼Œå°±å¯ä»¥è¿›å…¥ Q2 Pattern Extraction é˜¶æ®µï¼** ğŸ‰
