#!/usr/bin/env python3
"""
Main entry point for running Q1 drift analysis in batch on a pre-processed session.

This script reads a session directory created by `process_long_conversation.py`,
iterates through all sub-tasks (queries), and orchestrates the full Q1 
analysis pipeline (`chat2events` -> `events2guards`) for each one. It saves 
the final analysis results in the `data/2_runs` directory.
"""

import sys
import json
import pathlib
import subprocess
import argparse
import os
from typing import List, Dict, Any


from tools import chat2events, events2guards

def run_q1_analysis(
    session_dir: pathlib.Path,
    query_id: str,
    output_dir: pathlib.Path
) -> Dict[str, Any]:
    """
    å¯¹å•ä¸ªqueryè¿è¡ŒQ1åˆ†æ

    Args:
        session_dir: Sessionç›®å½•è·¯å¾„
        query_id: Query ID (å¦‚ 'q01')
        output_dir: è¾“å‡ºæ ¹ç›®å½• (data/2_runs)

    Returns:
        åˆ†æç»“æœæ‘˜è¦
    """
    query_dir = session_dir / 'pairs' / query_id
    goal_path = query_dir / 'goal.json'
    chat_path = query_dir / 'chat.md'

    # éªŒè¯æ–‡ä»¶å­˜åœ¨
    if not goal_path.exists():
        return {"error": f"goal.json not found in {query_dir}"}
    if not chat_path.exists():
        return {"error": f"chat.md not found in {query_dir}"}

    # è¯»å–goal.jsonè·å–run_id
    with open(goal_path) as f:
        goal = json.load(f)

    run_id = goal.get('run_id', f"{session_dir.name}_{query_id}")

    # åˆ›å»ºrunç›®å½•
    run_dir = output_dir / run_id
    run_dir.mkdir(parents=True, exist_ok=True)

    # åˆ›å»ºrawå­ç›®å½•
    raw_dir = run_dir / 'raw'
    raw_dir.mkdir(exist_ok=True)

    # å¤åˆ¶æ–‡ä»¶åˆ°runç›®å½•
    import shutil
    shutil.copy(goal_path, run_dir / 'goal.json')
    shutil.copy(chat_path, raw_dir / 'cursor.md')

    print(f"   ğŸ“ Created run directory: {run_dir.relative_to(output_dir.parent)}")

    # Step 1: Run chat2events
    print(f"   ğŸ”„ Running chat2events...")
    try:
        chat2events.main(str(run_dir))
        print(f"   âœ… Events extracted")
    except Exception as e:
        print(f"   âŒ chat2events error: {e}")
        return {"error": f"chat2events error: {e}"}

    # Step 2: Run events2guards
    print(f"   ğŸ›¡ï¸  Running events2guards...")
    try:
        events2guards.main(str(run_dir))
        print(f"   âœ… Guards calculated")
    except Exception as e:
        print(f"   âŒ events2guards error: {e}")
        return {"error": f"events2guards error: {e}"}

    # è¯»å–ç»“æœç»Ÿè®¡
    guards_path = run_dir / 'guards.jsonl'

    if not guards_path.exists():
        return {"error": "guards.jsonl not generated"}

    # ç»Ÿè®¡drift
    drift_count = 0
    warn_count = 0
    rollback_count = 0

    with open(guards_path) as f:
        for line in f:
            guard = json.loads(line)
            action = guard.get('action', 'ok')
            if action == 'warn':
                warn_count += 1
                drift_count += 1
            elif action == 'rollback':
                rollback_count += 1
                drift_count += 1

    return {
        "run_id": run_id,
        "query_id": query_id,
        "status": "success",
        "drift_events": drift_count,
        "warnings": warn_count,
        "rollbacks": rollback_count
    }


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(
        description="æ‰¹é‡è¿è¡ŒQ1åˆ†æ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # åˆ†ææ•´ä¸ªsession
  python tools/run_q1_batch.py data/1_sessions/s_2025-10-26-10-00-00_cursor

  # åªåˆ†æç‰¹å®šqueries
  python tools/run_q1_batch.py data/1_sessions/s_2025-10-26-10-00-00_cursor --queries q01,q02

  # æŒ‡å®šè¾“å‡ºç›®å½•
  python tools/run_q1_batch.py data/1_sessions/s_2025-10-26-10-00-00_cursor --output data/my_runs
        """
    )

    parser.add_argument(
        'session_dir',
        help='Sessionç›®å½•è·¯å¾„ (å¦‚ data/1_sessions/s_2025-10-26-10-00-00_cursor)'
    )
    parser.add_argument(
        '--queries',
        help='é€—å·åˆ†éš”çš„query IDs (å¦‚ q01,q02,q03)ã€‚ä¸æŒ‡å®šåˆ™å¤„ç†æ‰€æœ‰queries',
        default=None
    )
    parser.add_argument(
        '--output',
        help='è¾“å‡ºç›®å½• (é»˜è®¤: data/2_runs)',
        default='data/2_runs'
    )

    args = parser.parse_args()

    # éªŒè¯sessionç›®å½•
    session_dir = pathlib.Path(args.session_dir)
    if not session_dir.exists():
        print(f"âŒ Error: Session directory not found: {session_dir}")
        sys.exit(1)

    pairs_dir = session_dir / 'pairs'
    if not pairs_dir.exists():
        print(f"âŒ Error: pairs/ directory not found in {session_dir}")
        sys.exit(1)

    # è·å–queryåˆ—è¡¨
    if args.queries:
        query_ids = [q.strip() for q in args.queries.split(',')]
    else:
        # è‡ªåŠ¨å‘ç°æ‰€æœ‰queries
        query_dirs = sorted(pairs_dir.glob('q*'))
        query_ids = [d.name for d in query_dirs if d.is_dir()]

    if not query_ids:
        print(f"âŒ Error: No queries found in {pairs_dir}")
        sys.exit(1)

    output_dir = pathlib.Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    # å¼€å§‹æ‰¹å¤„ç†
    print(f"ğŸš€ Starting Q1 Batch Analysis")
    print(f"=" * 80)
    print(f"ğŸ“ Session: {session_dir}")
    print(f"ğŸ“Š Queries: {len(query_ids)}")
    print(f"ğŸ’¾ Output: {output_dir}")
    print(f"=" * 80)

    results = []

    for i, query_id in enumerate(query_ids, 1):
        print(f"\n{'=' * 60}")
        print(f"Processing {i}/{len(query_ids)}: {query_id}")
        print(f"{'=' * 60}")

        result = run_q1_analysis(session_dir, query_id, output_dir)
        results.append(result)

        if 'error' in result:
            print(f"   âŒ Failed: {result['error']}")
        else:
            status_emoji = "âœ…" if result['drift_events'] == 0 else "âš ï¸"
            print(f"   {status_emoji} Completed")
            if result['drift_events'] > 0:
                print(f"      - Drift Events: {result['drift_events']}")
                print(f"      - Warnings: {result['warnings']}")
                print(f"      - Rollbacks: {result['rollbacks']}")

    # æœ€ç»ˆæ€»ç»“
    print(f"\n{'=' * 80}")
    print(f"âœ… Q1 BATCH ANALYSIS COMPLETE")
    print(f"{'=' * 80}")

    successful = [r for r in results if 'error' not in r]
    failed = [r for r in results if 'error' in r]
    drift_detected = [r for r in successful if r.get('drift_events', 0) > 0]

    print(f"ğŸ“Š Summary:")
    print(f"   - Total Queries: {len(results)}")
    print(f"   - Successful: {len(successful)}")
    print(f"   - Failed: {len(failed)}")
    print(f"   - Drift Detected: {len(drift_detected)}")

    if drift_detected:
        print(f"\nâš ï¸  Queries with Drift:")
        for r in drift_detected:
            print(f"   - {r['query_id']}: {r['drift_events']} events "
                  f"({r['warnings']} warns, {r['rollbacks']} rollbacks)")

    # ä¿å­˜summary
    summary_path = output_dir / f"{session_dir.name}_summary.json"
    with open(summary_path, 'w') as f:
        json.dump(results, f, indent=2)

    print(f"\nğŸ’¾ Summary saved: {summary_path}")

    # é€€å‡ºç 
    if failed:
        print(f"\nâš ï¸  Warning: {len(failed)} queries failed")
        sys.exit(1)
    else:
        print(f"\nğŸ‰ All queries processed successfully!")
        sys.exit(0)


if __name__ == "__main__":
    main()
